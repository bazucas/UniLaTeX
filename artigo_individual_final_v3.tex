\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage[style=apa, backend=biber]{biblatex}
\addbibresource{individual.bib} % Nome do arquivo de bibliografia
\usepackage{csquotes} % Necessário para citações com babel
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst} % Pacote para indentar o primeiro parágrafo
\usepackage{newtxtext,newtxmath} % Usa fontes Times modernas
\usepackage{xcolor} % Pacote para cores
\usepackage{fancyhdr} % Para personalização do rodapé
\usepackage{titlesec} % Para personalizar títulos e subtítulos

% Configuração de Margens e Espaçamento
\geometry{a4paper, margin=2.5cm}
\setstretch{1.5}

% Configuração de Tamanhos de Fonte e Espaçamento para Seções
\titleformat{\section} % Títulos principais numerados
{\normalfont\fontsize{14}{17}\bfseries}{\thesection}{1em}{}
\titleformat*{\section} % Títulos principais não numerados
{\normalfont\fontsize{14}{17}\bfseries}
\titleformat{\subsection} % Subtítulos
{\normalfont\fontsize{12}{15}\bfseries}{\thesubsection}{1em}{}

% Ajuste de Espaçamento para Seções
\titlespacing{\section}
{0pt}{1.5em}{1em}
\titlespacing*{\section}
{0pt}{1.5em}{1em}
\titlespacing{\subsection}
{0pt}{1.2em}{0.8em}

% Configuração de Rodapé com Numeração
\pagestyle{fancy}
\fancyhf{} % Limpa cabeçalho e rodapé
\fancyfoot[R]{\thepage} % Numeração no canto inferior direito
\renewcommand{\headrulewidth}{0pt} % Remove linha do cabeçalho
\renewcommand{\footrulewidth}{0pt} % Remove linha do rodapé

% Configuração de Cores
\definecolor{barraazul}{RGB}{0, 51, 153}

% Numeração das seções sem números iniciais adicionais
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}.}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}.}

% Redefinição do Cabeçalho da Bibliografia
\defbibheading{bibliography}{
	\section*{Referências Bibliográficas}
	\addcontentsline{toc}{section}{Referências Bibliográficas}
	\thispagestyle{fancy} % Garante que o rodapé seja consistente
}

% Garante que o estilo de página seja 'fancy' na bibliografia
\AtBeginBibliography{\pagestyle{fancy}}

% Ajuste para indentação de parágrafos
\setlength{\parindent}{1.25cm}

\begin{document}
	
	% Capa
\begin{titlepage}
	\centering
	\vspace*{-2cm} % Reduz a margem superior da página de título
	
	% Ajusta as imagens para remover espaçamentos internos (se houver)
	\raisebox{-0.5\height}{\includegraphics[width=0.4\textwidth]{iscte.png}}%
	\hfill%
	\raisebox{-0.46\height}{\includegraphics[width=0.4\textwidth]{ista.png}}\\[0.5cm]
	
	\noindent
	{\color{barraazul}\rule{\textwidth}{1mm}} % Barra azul horizontal
	\\[1cm]
	
	{\LARGE  \textbf{Emoções e Heurísticas na Tomada de Decisão: Desafios para a Inteligência Artificial Emocional} \par}
	\vspace{3cm}
	
	{\Large \textbf{Mestrado em Inteligência Artificial}} \par
	\vspace{1cm}
	{\large \textbf{Unidade Curricular: Cognição e Emoção}} \par
	\vspace{3cm}
	
	{\large \textbf{Aluno: Luís Ricardo Silva Inácio}} \par
	{\large \textbf{Número: 129074}} \par
	\vspace{3cm}
	

	
	{\large \textbf{Professora: Doutora Cristiane da Anunciação Souza}} \par
	\vfill
	
	\vspace{0.5cm}
	{\large \textbf{Data de Entrega: 29 de novembro de 2024}} \par
\end{titlepage}

	
	% Costas da Capa (Em branco)
	\newpage
	\thispagestyle{empty}
	\mbox{}
	\newpage
	
	% Configuração para numeração romana
	\pagenumbering{roman}
	
	% Resumo
	\section*{Resumo} \addcontentsline{toc}{section}{Resumo}
	
	Este artigo responde a duas questões centrais relacionadas à cognição e emoção. Primeiro, analisa o papel das emoções no uso de heurísticas, considerando os impactos positivos e negativos, e compara heurísticas humanas e de inteligência artificial (IA), incluindo sua flexibilidade e limitações. Exemplos práticos são fornecidos, como assistentes virtuais (e.g., Alexa da Amazon, ChatGPT) e algoritmos de recrutamento automatizados, para ilustrar como heurísticas influenciam respostas emocionais nesses contextos. Segundo, comenta sobre a complexidade e ambiguidade da linguagem, avaliando as implicações éticas e de privacidade na criação de sistemas de IA emocional. Fundamenta-se na literatura para exemplificar os desafios e lacunas na interpretação emocional, devido a nuances como sarcasmo, ironia e expressões culturais, debatendo se estas limitações são intrínsecas ou podem ser superadas com progresso técnico. Questões éticas e de privacidade são aprofundadas, destacando os riscos de manipulação emocional e invasão de privacidade na recolha de dados emocionais, bem como o uso de IA emocional em publicidade e política. Por fim, propõem-se abordagens para mitigar esses riscos, enfatizando a importância de modelos explicáveis, conformidade regulatória e educação dos utilizadores. Conclui-se que o desenvolvimento de IA emocional requer uma abordagem ética e interdisciplinar, equilibrando avanços tecnológicos com o respeito pelos valores humanos.
		
	\vspace{4em}
	
	\noindent\textbf{Palavras-Chave:} \normalsize{Emoções, Heurísticas Cognitivas, Tomada de Decisão, Inteligência Artificial Emocional, Complexidade da Linguagem, Ética em IA, Manipulação Emocional.}
	
	\newpage	
	
	% Configuração para numeração arábica
	\pagenumbering{arabic}
	
	% Introdução
	\section{Introdução}
	
	As emoções desempenham um papel fundamental na forma como os indivíduos processam informações e tomam decisões. Elas influenciam directamente o uso de heurísticas, estratégias cognitivas que facilitam a tomada de decisões em contextos complexos ou incertos \parencite{kahneman1974}. Paralelamente, a linguagem, como meio de expressão emocional, é inerentemente complexa e ambígua, representando um desafio significativo para a criação de sistemas de inteligência artificial (IA) capazes de compreender e responder às emoções humanas \parencite{chomsky1965}. Este artigo explora a intersecção entre emoções, heurísticas e linguagem na cognição humana e discute as implicações técnicas, éticas e de privacidade na criação de sistemas de IA emocional. Além disso, propõe abordagens para mitigar os riscos associados e promover o desenvolvimento de IA emocionalmente inteligente e ética, alinhada com as directrizes de design ético propostas pelo \textcite{ieee2019}.
	
	\section{O Papel das Emoções nas Heurísticas e a Complexidade da Linguagem na IA Emocional}
	
	\subsection{Heurísticas, Emoções e Linguagem: Uma Introdução Teórica}
	
	\textcite{kahneman1974} definiram heurísticas como mecanismos que permitem aos indivíduos lidar com problemas de forma eficiente, utilizando uma quantidade limitada de recursos cognitivos. Estas estratégias são particularmente úteis em situações em que o tempo ou as informações disponíveis são escassas. No entanto, as heurísticas não são infalíveis e podem levar a erros ou vieses cognitivos. As emoções influenciam directamente o uso de heurísticas, funcionando como atalhos que podem ajudar ou prejudicar decisões, dependendo do contexto \parencite{slovic2007}.
	
	A linguagem é o meio pelo qual as emoções são frequentemente expressas e interpretadas. Conforme descrito por \textcite{chomsky1965}, a linguagem humana é complexa e permite uma variedade infinita de expressões. Esta complexidade apresenta desafios significativos para a IA, que necessita de interpretar correctamente nuances culturais, contextuais e emocionais para compreender as emoções humanas e responder de forma adequada. Apesar dos avanços no processamento de linguagem natural, a IA ainda apresenta limitações para entender e replicar estas subtilezas, o que pode gerar lacunas e equívocos na interpretação emocional \parencite{russell2020}.
	
	\subsection{Impactos Positivos das Emoções no Uso de Heurísticas e IA Emocional}
	
	As emoções podem facilitar decisões rápidas e eficientes através de heurísticas. \textcite{isen2001} destaca que estados emocionais positivos, como a felicidade, podem ampliar a criatividade e a flexibilidade cognitiva. Indivíduos felizes tendem a adoptar uma abordagem mais global, resultando na aplicação de heurísticas adaptativas em contextos complexos. Em ambientes de trabalho, gestores com estados emocionais positivos são mais propensos a tomar decisões inovadoras e a resolver problemas de forma eficaz.
	
	Em sistemas de IA, a compreensão e incorporação de estados emocionais podem melhorar a interacção homem-máquina, tornando-a mais natural e eficaz. Assistentes virtuais como a Alexa da Amazon e o ChatGPT utilizam heurísticas para interpretar e responder a comandos de linguagem natural, adaptando-se ao contexto emocional do utilizador. Por exemplo, se um utilizador expressa frustração, o sistema pode ajustar o seu tom de resposta para ser mais empático e oferecer assistência adicional. Esta adaptabilidade aumenta a satisfação do utilizador e promove uma experiência mais personalizada.
	
	Além disso, aplicações de IA emocional estão a ser implementadas na área da saúde mental, oferecendo suporte terapêutico inicial. Programas que detectam sinais de ansiedade ou depressão podem encaminhar utilizadores para profissionais de saúde ou fornecer técnicas de relaxamento, demonstrando o potencial positivo destas tecnologias quando utilizadas de forma ética.
	
	\subsection{Desafios na Interpretação da Linguagem Emocional pela IA}
	
	A ambiguidade e a complexidade da linguagem emocional representam obstáculos significativos para a IA emocional. Frases como “Estou bem” podem variar em significado, desde sinceridade até sarcasmo, dependendo do tom, da entoação e do contexto. Modelos de processamento de linguagem natural actuais, embora tenham avançado na interpretação de texto, ainda enfrentam dificuldades na compreensão das nuances emocionais implícitas \parencite{russell2020}.
	
	A IA frequentemente interpreta a linguagem de forma literal, falhando em captar sarcasmo, ironia ou humor. Estas limitações levantam a questão de saber se são intrínsecas à natureza da linguagem humana ou se podem ser superadas com progresso técnico. Alguns pesquisadores argumentam que avanços em aprendizagem profunda e redes neuronais podem eventualmente permitir que a IA compreenda melhor estas subtilezas, enquanto outros acreditam que certos aspectos da comunicação humana, como contextos culturais e experiências pessoais, são demasiado complexos para serem totalmente codificados.
	
	\subsection{Impactos Negativos das Emoções e da Linguagem Ambígua na IA e na Tomada de Decisão}
	
	Embora as emoções possam facilitar decisões, também podem introduzir vulnerabilidades significativas. Emoções intensas podem distorcer julgamentos, levando a decisões enviesadas ou irracionais. Na IA, os sistemas que procuram simular ou interpretar emoções enfrentam o desafio de evitar a reprodução desses enviesamentos. \textcite{russell2020} alertam que modelos que imitam heurísticas emocionais humanas podem inadvertidamente incorporar vieses culturais ou sociais, prejudicando a fiabilidade e a ética das decisões automatizadas. Por exemplo, algoritmos de recrutamento automatizados podem perpetuar desigualdades sociais ao favorecer candidatos de determinados grupos demográficos, se treinados com dados enviesados.
	
	A linguagem ambígua exacerba estes desafios. Sistemas de IA podem interpretar mal o sarcasmo, a ironia ou o humor, resultando em respostas inadequadas ou até prejudiciais. Esta falha na interpretação pode levar a decisões empresariais baseadas em dados imprecisos, afectando estratégias de negócio e satisfação do cliente. Em contextos críticos, como assistência médica, mal-entendidos podem ter consequências graves, destacando a importância de abordar estas limitações.
	
	\subsection{Implicações Éticas e de Privacidade na Criação de IA Emocional}
	
	O desenvolvimento de sistemas de IA emocional levanta questões éticas significativas. A manipulação emocional é uma preocupação central; sistemas que monitorizam emoções podem explorar vulnerabilidades dos utilizadores, especialmente em contextos comerciais, influenciando decisões de compra e violando a autonomia dos consumidores. Além disso, a recolha de dados emocionais sensíveis levanta questões de privacidade. Há o perigo de que tais dados sejam utilizados para vigilância, discriminação ou outros fins maliciosos.
	
	A falta de transparência nos sistemas de IA emocional dificulta a compreensão de como as decisões são tomadas, comprometendo a confiança dos utilizadores \parencite{russell2020}. Sem uma explicação clara de como um sistema interpreta emoções e toma decisões, é difícil identificar e corrigir possíveis vieses ou erros. Além disso, o uso de IA emocional em publicidade e política levanta preocupações adicionais. Empresas podem utilizar IA para manipular emoções dos consumidores, influenciando escolhas de forma pouco ética. Em cenários políticos, a IA pode ser empregada para direcionar propaganda personalizada, potencialmente manipulando opiniões públicas e afectando processos democráticos.
	
	\subsection{Abordagens para Mitigar Riscos Éticos e de Privacidade}
	
	Para abordar estes desafios, é essencial o desenvolvimento de modelos explicáveis que permitam aos utilizadores entender como as emoções são detectadas e influenciam as decisões do sistema \parencite{russell2020}. A explicabilidade aumenta a confiança do utilizador e permite a identificação de possíveis vieses ou falhas no sistema.
	
	A aplicação rigorosa de regulamentações como o Regulamento Geral de Protecção de Dados (RGPD) é fundamental para proteger a privacidade dos utilizadores. Técnicas como aprendizagem federada podem reduzir riscos de privacidade, permitindo treinar modelos sem transferir dados sensíveis para servidores centrais. Além disso, a implementação de protocolos de segurança avançados e a anonimização de dados podem prevenir acessos não autorizados e uso indevido de informações pessoais.
	
	A educação dos utilizadores sobre os riscos associados ao partilhar dados emocionais e a promoção de controlos sobre como as suas informações são usadas são cruciais para capacitar os indivíduos e fomentar interacções mais seguras. Campanhas de literacia digital e transparência nas políticas de privacidade podem contribuir para uma utilização mais consciente e responsável da IA emocional.
	
	\subsection{Integração Ética de Heurísticas Emocionais na IA}
	
	\textcite{gigerenzer2009} sugerem que as heurísticas humanas evoluíram para lidar com incertezas. A integração de heurísticas emocionais em sistemas de IA apresenta oportunidades e riscos. Para integrar heurísticas emocionais de forma ética, é necessário:
	
	\begin{itemize}
		\item \textbf{Transparência nos algoritmos}: Desenvolver algoritmos cujos processos de tomada de decisão possam ser auditados e compreendidos.
		\item \textbf{Diversidade nos dados de treino}: Utilizar conjuntos de dados que representem a diversidade cultural e emocional da população.
		\item \textbf{Supervisão humana}: Manter supervisão nas decisões críticas.
		\item \textbf{Ética incorporada}: Incluir princípios éticos no design dos sistemas, alinhados com normas internacionais como as propostas pelo \textcite{ieee2019}.
		\item \textbf{\textit{Feedback} contínuo}: Implementar mecanismos para que os utilizadores forneçam \textit{feedback}.
		\item \textbf{Avaliação contínua}: Realizar avaliações periódicas dos sistemas para garantir alinhamento com valores éticos.
	\end{itemize}
	
	A colaboração interdisciplinar entre engenheiros, psicólogos, filósofos e legisladores é essencial para abordar os desafios complexos na integração de emoções e heurísticas na IA. Somente através de uma abordagem holística é possível desenvolver sistemas que sejam tecnicamente robustos e eticamente responsáveis.
	
	\section{Conclusão}
	
	As emoções e a linguagem desempenham papéis cruciais na cognição humana e na tomada de decisão através de heurísticas. Embora possam facilitar decisões rápidas e adaptativas, também introduzem desafios significativos para a criação de sistemas de IA emocional. A complexidade e ambiguidade da linguagem humana representam obstáculos técnicos substanciais, enquanto questões éticas e de privacidade exigem atenção cuidadosa.
	
	Para maximizar os benefícios e mitigar os riscos, é essencial que desenvolvedores, reguladores e utilizadores colaborem na formulação de soluções éticas e transparentes. Conforme enfatizado por \textcite{russell2020}, o futuro da IA emocional depende da sua capacidade de respeitar os direitos humanos e promover interacções mais empáticas e seguras.
	
	O progresso nesta área requer um compromisso contínuo com a investigação interdisciplinar. Iniciativas de regulamentação e padrões internacionais, como as propostas pelo \textcite{ieee2019}, desempenham um papel crucial na orientação do desenvolvimento ético da IA. Além disso, a educação e sensibilização pública sobre o funcionamento e os impactos da IA emocional são fundamentais para promover uma sociedade informada e capaz de tomar decisões conscientes sobre o uso destas tecnologias.
	
	Em última análise, a integração bem-sucedida de emoções e heurísticas na IA dependerá da nossa capacidade de compreender profundamente a natureza humana e de traduzir esse conhecimento em sistemas tecnológicos que reflitam não apenas a inteligência, mas também a sabedoria e a ética humanas. A responsabilidade colectiva na abordagem destes desafios determinará se a IA emocional se tornará uma ferramenta para o bem comum ou uma fonte de novas desigualdades e riscos sociais.
	
	\newpage
	
	% Referências
	\printbibliography
	
\end{document}
